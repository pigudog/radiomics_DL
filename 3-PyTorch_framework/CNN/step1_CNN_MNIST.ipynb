{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Convolutional Neural Networks\n",
    "\n",
    "    The inputs and layers in convolutional networks are somewhat different from traditional neural networks and need to be redesigned. The training module remains basically the same.\n",
    "\n",
    "Convolutional neural networks or CNNs have been particularly effective in tasks where the input data is grid-like topology such as image pixel data. They distinguish themselves from traditional neural nets as they contain Convolutional layers, Pooling layers, and Fully Connected layers. Despite the architectural differences, the training process, specifically the propagation and weight update steps, remain largely the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets,transforms \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### con - relu - pooling\n",
    "ReLU stands for Rectified Linear Unit and it's one of the most commonly used activation functions in neural networks and deep learning models.\n",
    "\n",
    "An activation function in a neural network defines how the weighted sum of the input is transformed into an output from a node or nodes in a layer of the network. In other words, they decide whether a given neuron should be activated or not based on the weighted sum.\n",
    "\n",
    "ReLU is mathematically defined as f(x) = max(0, x). The function returns x if it is greater than 0, otherwise, it returns 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, load the data\n",
    "\n",
    "    Separately construct the training set and test set (validation set).\n",
    "\n",
    "    Use DataLoader to iterate over the data.\n",
    "\n",
    "In the realm of machine learning, working with datasets always starts with loading the data and splitting it into a training set and a *test* set (with an **optional** *validation* set). The training set is used to train the model, while the test set (and/or validation set) is used to evaluate the model's performance. The DataLoader is a utility function commonly used in PyTorch that provides an iterator over the dataset, allowing for easy batch processing and shuffling of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the hyperparameters\n",
    "input_size = 28  # The size of the image is 28*28\n",
    "num_classes = 10  # the number if classification categories\n",
    "num_epochs = 10  # the number of training cycles\n",
    "batch_size = 64  # the number of images handled in a batch，64\n",
    "\n",
    "\n",
    "# you load the training and testing sets. \n",
    "# You are using the MNIST dataset here, also known as the handwritten digits dataset. \n",
    "# This dataset includes 60,000 training samples and 10,000 testing samples. \n",
    "# You download the dataset and convert each image into tensor format.\n",
    "# TRAIN\n",
    "train_dataset = datasets.MNIST(root='./data',  \n",
    "                            train=True,   \n",
    "                            transform=transforms.ToTensor(),  \n",
    "                            download=True) \n",
    "\n",
    "# TEST\n",
    "test_dataset = datasets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "# CONSTRUCT\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Convolutional Network Module\n",
    "\n",
    "    Generally, the convolutional layer, ReLU layer, and pooling layer can be combined into a package.\n",
    "    \n",
    "    Be aware that the final result of the convolution is still a feature map. This map needs to be converted into a vector to perform classification or regression tasks.\n",
    "\n",
    "In Convolutional Neural Networks (CNNs), convolutions, nonlinear activations (like ReLU), and pooling operations are typically used in conjunction to extract increasingly complex features from input data. \n",
    "\n",
    "After extracting features through these layers, the data still exists in a grid-like (image) format. Before connecting to a fully connected layer for classification or regression, the data must be flattened or transformed from a matrix into a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         # 输入大小 (1, 28, 28)\n",
    "            ## Conv2d + ReLU + MaxPooling\n",
    "            ### channels input and chanels output is important!\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              # 灰度图\n",
    "                out_channels=16,            # 要得到几多少个特征图\n",
    "                kernel_size=5,              # 卷积核大小\n",
    "                stride=1,                   # 步长\n",
    "                padding=2,                  # 如果希望卷积后大小跟原来一样，需要设置padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # 输出的特征图为 (16, 28, 28)\n",
    "            nn.ReLU(),                      # relu层\n",
    "            nn.MaxPool2d(kernel_size=2),    # 进行池化操作（2x2 区域）, 输出结果为： (16, 14, 14)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         # 下一个套餐的输入 (16, 14, 14)\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     # 输出 (32, 14, 14)\n",
    "            nn.ReLU(),                      # relu层\n",
    "            nn.MaxPool2d(2),                # 输出 (32, 7, 7)\n",
    "        )\n",
    "        # Fully connected layer: 32 * 7 * 7 = 1568\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)   # 全连接层得到的结果\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)           # flatten操作，结果为：(batch_size, 32 * 7 * 7)\n",
    "        output = self.out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy as the evaluation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's simply calculated as the proportion of correct predictions over total predictions. \n",
    "\n",
    "However, while simple and easy to interpret, accuracy may not be suitable for all scenarios especially when dealing with imbalanced datasets. \n",
    "\n",
    "Other metrics like precision, recall, F1-score, or even ROC AUC might be more appropriate depending on the specific problem and data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    pred = torch.max(predictions.data, 1)[1] \n",
    "    rights = pred.eq(labels.data.view_as(pred)).sum() \n",
    "    return rights, len(labels) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:\t 0\n",
      "当前epoch: 0 [0/60000 (0%)]\t损失: 2.302474\t训练集准确率: 9.38%\t测试集正确率: 25.36%\n",
      "当前epoch: 0 [6400/60000 (11%)]\t损失: 0.268418\t训练集准确率: 76.56%\t测试集正确率: 91.67%\n",
      "当前epoch: 0 [12800/60000 (21%)]\t损失: 0.390526\t训练集准确率: 84.58%\t测试集正确率: 94.60%\n",
      "当前epoch: 0 [19200/60000 (32%)]\t损失: 0.183719\t训练集准确率: 88.06%\t测试集正确率: 96.39%\n",
      "当前epoch: 0 [25600/60000 (43%)]\t损失: 0.142947\t训练集准确率: 90.11%\t测试集正确率: 96.77%\n",
      "当前epoch: 0 [32000/60000 (53%)]\t损失: 0.099231\t训练集准确率: 91.42%\t测试集正确率: 97.38%\n",
      "当前epoch: 0 [38400/60000 (64%)]\t损失: 0.115175\t训练集准确率: 92.35%\t测试集正确率: 96.84%\n",
      "当前epoch: 0 [44800/60000 (75%)]\t损失: 0.027719\t训练集准确率: 93.03%\t测试集正确率: 97.86%\n",
      "当前epoch: 0 [51200/60000 (85%)]\t损失: 0.075959\t训练集准确率: 93.59%\t测试集正确率: 97.50%\n",
      "当前epoch: 0 [57600/60000 (96%)]\t损失: 0.126686\t训练集准确率: 94.01%\t测试集正确率: 97.90%\n",
      "epoch:\t 1\n",
      "当前epoch: 1 [0/60000 (0%)]\t损失: 0.074506\t训练集准确率: 98.44%\t测试集正确率: 97.95%\n",
      "当前epoch: 1 [6400/60000 (11%)]\t损失: 0.139104\t训练集准确率: 97.59%\t测试集正确率: 97.87%\n",
      "当前epoch: 1 [12800/60000 (21%)]\t损失: 0.091080\t训练集准确率: 97.89%\t测试集正确率: 98.04%\n",
      "当前epoch: 1 [19200/60000 (32%)]\t损失: 0.054014\t训练集准确率: 97.92%\t测试集正确率: 98.21%\n",
      "当前epoch: 1 [25600/60000 (43%)]\t损失: 0.083717\t训练集准确率: 97.92%\t测试集正确率: 98.26%\n",
      "当前epoch: 1 [32000/60000 (53%)]\t损失: 0.058893\t训练集准确率: 98.02%\t测试集正确率: 97.82%\n",
      "当前epoch: 1 [38400/60000 (64%)]\t损失: 0.044280\t训练集准确率: 98.08%\t测试集正确率: 98.47%\n",
      "当前epoch: 1 [44800/60000 (75%)]\t损失: 0.057430\t训练集准确率: 98.09%\t测试集正确率: 98.61%\n",
      "当前epoch: 1 [51200/60000 (85%)]\t损失: 0.022044\t训练集准确率: 98.10%\t测试集正确率: 98.52%\n",
      "当前epoch: 1 [57600/60000 (96%)]\t损失: 0.005940\t训练集准确率: 98.14%\t测试集正确率: 98.76%\n",
      "epoch:\t 2\n",
      "当前epoch: 2 [0/60000 (0%)]\t损失: 0.180623\t训练集准确率: 96.88%\t测试集正确率: 98.67%\n",
      "当前epoch: 2 [6400/60000 (11%)]\t损失: 0.010747\t训练集准确率: 98.62%\t测试集正确率: 98.46%\n",
      "当前epoch: 2 [12800/60000 (21%)]\t损失: 0.003561\t训练集准确率: 98.45%\t测试集正确率: 98.60%\n",
      "当前epoch: 2 [19200/60000 (32%)]\t损失: 0.072868\t训练集准确率: 98.50%\t测试集正确率: 98.49%\n",
      "当前epoch: 2 [25600/60000 (43%)]\t损失: 0.005578\t训练集准确率: 98.54%\t测试集正确率: 98.77%\n",
      "当前epoch: 2 [32000/60000 (53%)]\t损失: 0.141238\t训练集准确率: 98.52%\t测试集正确率: 98.49%\n",
      "当前epoch: 2 [38400/60000 (64%)]\t损失: 0.008729\t训练集准确率: 98.53%\t测试集正确率: 98.67%\n",
      "当前epoch: 2 [44800/60000 (75%)]\t损失: 0.069723\t训练集准确率: 98.57%\t测试集正确率: 98.77%\n",
      "当前epoch: 2 [51200/60000 (85%)]\t损失: 0.011543\t训练集准确率: 98.59%\t测试集正确率: 98.88%\n",
      "当前epoch: 2 [57600/60000 (96%)]\t损失: 0.061950\t训练集准确率: 98.62%\t测试集正确率: 98.77%\n",
      "epoch:\t 3\n",
      "当前epoch: 3 [0/60000 (0%)]\t损失: 0.019965\t训练集准确率: 100.00%\t测试集正确率: 98.74%\n",
      "当前epoch: 3 [6400/60000 (11%)]\t损失: 0.004694\t训练集准确率: 99.16%\t测试集正确率: 98.80%\n",
      "当前epoch: 3 [12800/60000 (21%)]\t损失: 0.030500\t训练集准确率: 98.99%\t测试集正确率: 98.81%\n",
      "当前epoch: 3 [19200/60000 (32%)]\t损失: 0.075501\t训练集准确率: 98.96%\t测试集正确率: 98.65%\n",
      "当前epoch: 3 [25600/60000 (43%)]\t损失: 0.044547\t训练集准确率: 98.98%\t测试集正确率: 98.70%\n",
      "当前epoch: 3 [32000/60000 (53%)]\t损失: 0.053810\t训练集准确率: 98.93%\t测试集正确率: 98.92%\n",
      "当前epoch: 3 [38400/60000 (64%)]\t损失: 0.018210\t训练集准确率: 99.00%\t测试集正确率: 98.81%\n",
      "当前epoch: 3 [44800/60000 (75%)]\t损失: 0.025529\t训练集准确率: 99.00%\t测试集正确率: 98.77%\n",
      "当前epoch: 3 [51200/60000 (85%)]\t损失: 0.033087\t训练集准确率: 98.94%\t测试集正确率: 99.00%\n",
      "当前epoch: 3 [57600/60000 (96%)]\t损失: 0.027316\t训练集准确率: 98.92%\t测试集正确率: 98.77%\n",
      "epoch:\t 4\n",
      "当前epoch: 4 [0/60000 (0%)]\t损失: 0.173205\t训练集准确率: 95.31%\t测试集正确率: 98.87%\n",
      "当前epoch: 4 [6400/60000 (11%)]\t损失: 0.046835\t训练集准确率: 99.21%\t测试集正确率: 98.88%\n",
      "当前epoch: 4 [12800/60000 (21%)]\t损失: 0.081968\t训练集准确率: 99.21%\t测试集正确率: 99.01%\n",
      "当前epoch: 4 [19200/60000 (32%)]\t损失: 0.006396\t训练集准确率: 99.23%\t测试集正确率: 98.92%\n",
      "当前epoch: 4 [25600/60000 (43%)]\t损失: 0.031498\t训练集准确率: 99.22%\t测试集正确率: 98.86%\n",
      "当前epoch: 4 [32000/60000 (53%)]\t损失: 0.003462\t训练集准确率: 99.21%\t测试集正确率: 98.95%\n",
      "当前epoch: 4 [38400/60000 (64%)]\t损失: 0.016164\t训练集准确率: 99.21%\t测试集正确率: 99.10%\n",
      "当前epoch: 4 [44800/60000 (75%)]\t损失: 0.028088\t训练集准确率: 99.17%\t测试集正确率: 99.01%\n",
      "当前epoch: 4 [51200/60000 (85%)]\t损失: 0.038258\t训练集准确率: 99.13%\t测试集正确率: 99.03%\n",
      "当前epoch: 4 [57600/60000 (96%)]\t损失: 0.001478\t训练集准确率: 99.14%\t测试集正确率: 98.72%\n",
      "epoch:\t 5\n",
      "当前epoch: 5 [0/60000 (0%)]\t损失: 0.001684\t训练集准确率: 100.00%\t测试集正确率: 98.83%\n",
      "当前epoch: 5 [6400/60000 (11%)]\t损失: 0.006119\t训练集准确率: 99.26%\t测试集正确率: 99.04%\n",
      "当前epoch: 5 [12800/60000 (21%)]\t损失: 0.002408\t训练集准确率: 99.29%\t测试集正确率: 98.94%\n",
      "当前epoch: 5 [19200/60000 (32%)]\t损失: 0.001037\t训练集准确率: 99.22%\t测试集正确率: 98.91%\n",
      "当前epoch: 5 [25600/60000 (43%)]\t损失: 0.085512\t训练集准确率: 99.24%\t测试集正确率: 99.03%\n",
      "当前epoch: 5 [32000/60000 (53%)]\t损失: 0.000933\t训练集准确率: 99.25%\t测试集正确率: 99.06%\n",
      "当前epoch: 5 [38400/60000 (64%)]\t损失: 0.031006\t训练集准确率: 99.24%\t测试集正确率: 98.89%\n",
      "当前epoch: 5 [44800/60000 (75%)]\t损失: 0.003357\t训练集准确率: 99.25%\t测试集正确率: 99.02%\n",
      "当前epoch: 5 [51200/60000 (85%)]\t损失: 0.000894\t训练集准确率: 99.25%\t测试集正确率: 99.12%\n",
      "当前epoch: 5 [57600/60000 (96%)]\t损失: 0.006659\t训练集准确率: 99.26%\t测试集正确率: 98.59%\n",
      "epoch:\t 6\n",
      "当前epoch: 6 [0/60000 (0%)]\t损失: 0.010757\t训练集准确率: 100.00%\t测试集正确率: 98.92%\n",
      "当前epoch: 6 [6400/60000 (11%)]\t损失: 0.016911\t训练集准确率: 99.49%\t测试集正确率: 99.03%\n",
      "当前epoch: 6 [12800/60000 (21%)]\t损失: 0.034258\t训练集准确率: 99.53%\t测试集正确率: 99.09%\n",
      "当前epoch: 6 [19200/60000 (32%)]\t损失: 0.175025\t训练集准确率: 99.45%\t测试集正确率: 99.07%\n",
      "当前epoch: 6 [25600/60000 (43%)]\t损失: 0.018651\t训练集准确率: 99.45%\t测试集正确率: 99.16%\n",
      "当前epoch: 6 [32000/60000 (53%)]\t损失: 0.016849\t训练集准确率: 99.47%\t测试集正确率: 99.19%\n",
      "当前epoch: 6 [38400/60000 (64%)]\t损失: 0.042056\t训练集准确率: 99.47%\t测试集正确率: 99.08%\n",
      "当前epoch: 6 [44800/60000 (75%)]\t损失: 0.033563\t训练集准确率: 99.44%\t测试集正确率: 99.07%\n",
      "当前epoch: 6 [51200/60000 (85%)]\t损失: 0.001621\t训练集准确率: 99.45%\t测试集正确率: 98.96%\n",
      "当前epoch: 6 [57600/60000 (96%)]\t损失: 0.003347\t训练集准确率: 99.44%\t测试集正确率: 98.81%\n",
      "epoch:\t 7\n",
      "当前epoch: 7 [0/60000 (0%)]\t损失: 0.024737\t训练集准确率: 98.44%\t测试集正确率: 98.87%\n",
      "当前epoch: 7 [6400/60000 (11%)]\t损失: 0.001740\t训练集准确率: 99.60%\t测试集正确率: 99.22%\n",
      "当前epoch: 7 [12800/60000 (21%)]\t损失: 0.006954\t训练集准确率: 99.58%\t测试集正确率: 99.26%\n",
      "当前epoch: 7 [19200/60000 (32%)]\t损失: 0.031344\t训练集准确率: 99.59%\t测试集正确率: 98.95%\n",
      "当前epoch: 7 [25600/60000 (43%)]\t损失: 0.004882\t训练集准确率: 99.58%\t测试集正确率: 99.21%\n",
      "当前epoch: 7 [32000/60000 (53%)]\t损失: 0.004956\t训练集准确率: 99.57%\t测试集正确率: 99.14%\n",
      "当前epoch: 7 [38400/60000 (64%)]\t损失: 0.022395\t训练集准确率: 99.54%\t测试集正确率: 99.16%\n",
      "当前epoch: 7 [44800/60000 (75%)]\t损失: 0.001472\t训练集准确率: 99.54%\t测试集正确率: 99.15%\n",
      "当前epoch: 7 [51200/60000 (85%)]\t损失: 0.119639\t训练集准确率: 99.51%\t测试集正确率: 99.12%\n",
      "当前epoch: 7 [57600/60000 (96%)]\t损失: 0.010823\t训练集准确率: 99.50%\t测试集正确率: 99.12%\n",
      "epoch:\t 8\n",
      "当前epoch: 8 [0/60000 (0%)]\t损失: 0.000753\t训练集准确率: 100.00%\t测试集正确率: 99.13%\n",
      "当前epoch: 8 [6400/60000 (11%)]\t损失: 0.003412\t训练集准确率: 99.66%\t测试集正确率: 99.17%\n",
      "当前epoch: 8 [12800/60000 (21%)]\t损失: 0.008995\t训练集准确率: 99.69%\t测试集正确率: 99.09%\n",
      "当前epoch: 8 [19200/60000 (32%)]\t损失: 0.000790\t训练集准确率: 99.70%\t测试集正确率: 99.09%\n",
      "当前epoch: 8 [25600/60000 (43%)]\t损失: 0.086326\t训练集准确率: 99.68%\t测试集正确率: 99.13%\n",
      "当前epoch: 8 [32000/60000 (53%)]\t损失: 0.001541\t训练集准确率: 99.64%\t测试集正确率: 99.11%\n",
      "当前epoch: 8 [38400/60000 (64%)]\t损失: 0.001954\t训练集准确率: 99.62%\t测试集正确率: 99.06%\n",
      "当前epoch: 8 [44800/60000 (75%)]\t损失: 0.018688\t训练集准确率: 99.63%\t测试集正确率: 99.20%\n",
      "当前epoch: 8 [51200/60000 (85%)]\t损失: 0.000858\t训练集准确率: 99.63%\t测试集正确率: 99.04%\n",
      "当前epoch: 8 [57600/60000 (96%)]\t损失: 0.001677\t训练集准确率: 99.60%\t测试集正确率: 99.09%\n",
      "epoch:\t 9\n",
      "当前epoch: 9 [0/60000 (0%)]\t损失: 0.025392\t训练集准确率: 98.44%\t测试集正确率: 99.07%\n",
      "当前epoch: 9 [6400/60000 (11%)]\t损失: 0.002650\t训练集准确率: 99.69%\t测试集正确率: 99.09%\n",
      "当前epoch: 9 [12800/60000 (21%)]\t损失: 0.003321\t训练集准确率: 99.75%\t测试集正确率: 98.97%\n",
      "当前epoch: 9 [19200/60000 (32%)]\t损失: 0.004532\t训练集准确率: 99.72%\t测试集正确率: 99.18%\n",
      "当前epoch: 9 [25600/60000 (43%)]\t损失: 0.006264\t训练集准确率: 99.74%\t测试集正确率: 99.18%\n",
      "当前epoch: 9 [32000/60000 (53%)]\t损失: 0.000878\t训练集准确率: 99.71%\t测试集正确率: 99.16%\n",
      "当前epoch: 9 [38400/60000 (64%)]\t损失: 0.011409\t训练集准确率: 99.71%\t测试集正确率: 99.18%\n",
      "当前epoch: 9 [44800/60000 (75%)]\t损失: 0.002621\t训练集准确率: 99.70%\t测试集正确率: 99.14%\n",
      "当前epoch: 9 [51200/60000 (85%)]\t损失: 0.000022\t训练集准确率: 99.67%\t测试集正确率: 99.10%\n",
      "当前epoch: 9 [57600/60000 (96%)]\t损失: 0.005982\t训练集准确率: 99.67%\t测试集正确率: 99.20%\n"
     ]
    }
   ],
   "source": [
    "# A CNN named net is instantiated.\n",
    "net = CNN() \n",
    "# The loss function is defined as CrossEntropyLoss. This is often used in multi-class classification problems.\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "# The optimizer is defined as Adam (Adaptive Moment Estimation), which is a popular choice as it automatically adapts the learning rate during training.\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001) #定义优化器，普通的随机梯度下降算法\n",
    "\n",
    "# Next, the training cycle begins for a specified number of epochs:\n",
    "for epoch in range(num_epochs):\n",
    "    print('epoch:\\t',epoch)\n",
    "    #当前epoch的结果保存下来\n",
    "    train_rights = [] \n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):  #针对容器中的每一个批进行循环\n",
    "        net.train()                             \n",
    "        output = net(data) \n",
    "        loss = criterion(output, target) \n",
    "        optimizer.zero_grad() \n",
    "        loss.backward() \n",
    "        optimizer.step() \n",
    "        right = accuracy(output, target) \n",
    "        train_rights.append(right) \n",
    "\n",
    "        # In the code, every 100 batches, the system enters evaluation mode (net.eval()) and the process is repeated for the test loader to determine the CNN's accuracy on unseen data.\n",
    "        if batch_idx % 100 == 0: \n",
    "            \n",
    "            net.eval() \n",
    "            val_rights = [] \n",
    "            \n",
    "            for (data, target) in test_loader:\n",
    "                output = net(data) \n",
    "                right = accuracy(output, target) \n",
    "                val_rights.append(right)\n",
    "                \n",
    "            #准确率计算\n",
    "            train_r = (sum([tup[0] for tup in train_rights]), sum([tup[1] for tup in train_rights]))\n",
    "            val_r = (sum([tup[0] for tup in val_rights]), sum([tup[1] for tup in val_rights]))\n",
    "\n",
    "            print('当前epoch: {} [{}/{} ({:.0f}%)]\\t损失: {:.6f}\\t训练集准确率: {:.2f}%\\t测试集正确率: {:.2f}%'.format(\n",
    "                epoch, batch_idx * batch_size, len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), \n",
    "                loss.data, \n",
    "                100. * train_r[0].numpy() / train_r[1], \n",
    "                100. * val_r[0].numpy() / val_r[1]))\n",
    "\n",
    "# 5m 39.9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Current Epoch: 0 [0/60000 (0%)]\tLoss: 2.3095133304595947\tTrain Accuracy: 9.38%\tTest Accuracy: 15.44%\n",
      "Current Epoch: 0 [1600/60000 (11%)]\tLoss: 0.27368152141571045\tTrain Accuracy: 77.60%\tTest Accuracy: 91.23%\n",
      "Current Epoch: 0 [3200/60000 (21%)]\tLoss: 0.2977162003517151\tTrain Accuracy: 84.95%\tTest Accuracy: 93.43%\n",
      "Current Epoch: 0 [4800/60000 (32%)]\tLoss: 0.2923724055290222\tTrain Accuracy: 88.29%\tTest Accuracy: 96.37%\n",
      "Current Epoch: 0 [6400/60000 (43%)]\tLoss: 0.2790379524230957\tTrain Accuracy: 90.26%\tTest Accuracy: 96.54%\n",
      "Current Epoch: 0 [8000/60000 (53%)]\tLoss: 0.16589249670505524\tTrain Accuracy: 91.53%\tTest Accuracy: 97.37%\n",
      "Current Epoch: 0 [9600/60000 (64%)]\tLoss: 0.06248513236641884\tTrain Accuracy: 92.43%\tTest Accuracy: 97.53%\n",
      "Current Epoch: 0 [11200/60000 (75%)]\tLoss: 0.1336040198802948\tTrain Accuracy: 93.16%\tTest Accuracy: 97.67%\n",
      "Current Epoch: 0 [12800/60000 (85%)]\tLoss: 0.03855758160352707\tTrain Accuracy: 93.71%\tTest Accuracy: 97.69%\n",
      "Current Epoch: 0 [14400/60000 (96%)]\tLoss: 0.020169928669929504\tTrain Accuracy: 94.15%\tTest Accuracy: 97.82%\n",
      "Epoch: 1\n",
      "Current Epoch: 1 [0/60000 (0%)]\tLoss: 0.13141629099845886\tTrain Accuracy: 96.88%\tTest Accuracy: 97.81%\n",
      "Current Epoch: 1 [1600/60000 (11%)]\tLoss: 0.07862270623445511\tTrain Accuracy: 98.02%\tTest Accuracy: 97.86%\n",
      "Current Epoch: 1 [3200/60000 (21%)]\tLoss: 0.049191299825906754\tTrain Accuracy: 98.06%\tTest Accuracy: 98.24%\n",
      "Current Epoch: 1 [4800/60000 (32%)]\tLoss: 0.09013005346059799\tTrain Accuracy: 98.04%\tTest Accuracy: 98.16%\n",
      "Current Epoch: 1 [6400/60000 (43%)]\tLoss: 0.0693514347076416\tTrain Accuracy: 98.12%\tTest Accuracy: 98.19%\n",
      "Current Epoch: 1 [8000/60000 (53%)]\tLoss: 0.09313499927520752\tTrain Accuracy: 98.09%\tTest Accuracy: 98.18%\n",
      "Current Epoch: 1 [9600/60000 (64%)]\tLoss: 0.05496825650334358\tTrain Accuracy: 98.12%\tTest Accuracy: 98.10%\n",
      "Current Epoch: 1 [11200/60000 (75%)]\tLoss: 0.017132749781012535\tTrain Accuracy: 98.16%\tTest Accuracy: 98.38%\n",
      "Current Epoch: 1 [12800/60000 (85%)]\tLoss: 0.07682327926158905\tTrain Accuracy: 98.18%\tTest Accuracy: 98.51%\n",
      "Current Epoch: 1 [14400/60000 (96%)]\tLoss: 0.07306239008903503\tTrain Accuracy: 98.20%\tTest Accuracy: 98.23%\n",
      "Epoch: 2\n",
      "Current Epoch: 2 [0/60000 (0%)]\tLoss: 0.061748769134283066\tTrain Accuracy: 98.44%\tTest Accuracy: 98.62%\n",
      "Current Epoch: 2 [1600/60000 (11%)]\tLoss: 0.019439881667494774\tTrain Accuracy: 98.93%\tTest Accuracy: 98.48%\n",
      "Current Epoch: 2 [3200/60000 (21%)]\tLoss: 0.014375376515090466\tTrain Accuracy: 98.89%\tTest Accuracy: 98.34%\n",
      "Current Epoch: 2 [4800/60000 (32%)]\tLoss: 0.05780189111828804\tTrain Accuracy: 98.80%\tTest Accuracy: 98.47%\n",
      "Current Epoch: 2 [6400/60000 (43%)]\tLoss: 0.013703362084925175\tTrain Accuracy: 98.74%\tTest Accuracy: 98.71%\n",
      "Current Epoch: 2 [8000/60000 (53%)]\tLoss: 0.026852574199438095\tTrain Accuracy: 98.72%\tTest Accuracy: 98.55%\n",
      "Current Epoch: 2 [9600/60000 (64%)]\tLoss: 0.02557837776839733\tTrain Accuracy: 98.72%\tTest Accuracy: 98.66%\n",
      "Current Epoch: 2 [11200/60000 (75%)]\tLoss: 0.005757824517786503\tTrain Accuracy: 98.71%\tTest Accuracy: 98.85%\n",
      "Current Epoch: 2 [12800/60000 (85%)]\tLoss: 0.116046242415905\tTrain Accuracy: 98.73%\tTest Accuracy: 98.62%\n",
      "Current Epoch: 2 [14400/60000 (96%)]\tLoss: 0.02959776483476162\tTrain Accuracy: 98.72%\tTest Accuracy: 98.80%\n",
      "Epoch: 3\n",
      "Current Epoch: 3 [0/60000 (0%)]\tLoss: 0.0209728442132473\tTrain Accuracy: 98.44%\tTest Accuracy: 98.74%\n",
      "Current Epoch: 3 [1600/60000 (11%)]\tLoss: 0.06329873204231262\tTrain Accuracy: 98.89%\tTest Accuracy: 98.90%\n",
      "Current Epoch: 3 [3200/60000 (21%)]\tLoss: 0.014047239907085896\tTrain Accuracy: 99.00%\tTest Accuracy: 98.83%\n",
      "Current Epoch: 3 [4800/60000 (32%)]\tLoss: 0.008408249355852604\tTrain Accuracy: 99.03%\tTest Accuracy: 98.82%\n",
      "Current Epoch: 3 [6400/60000 (43%)]\tLoss: 0.11186525225639343\tTrain Accuracy: 98.98%\tTest Accuracy: 98.80%\n",
      "Current Epoch: 3 [8000/60000 (53%)]\tLoss: 0.13269610702991486\tTrain Accuracy: 98.96%\tTest Accuracy: 98.74%\n",
      "Current Epoch: 3 [9600/60000 (64%)]\tLoss: 0.021401436999440193\tTrain Accuracy: 98.95%\tTest Accuracy: 98.83%\n",
      "Current Epoch: 3 [11200/60000 (75%)]\tLoss: 0.0075522358529269695\tTrain Accuracy: 98.94%\tTest Accuracy: 98.64%\n",
      "Current Epoch: 3 [12800/60000 (85%)]\tLoss: 0.017522837966680527\tTrain Accuracy: 98.92%\tTest Accuracy: 98.74%\n",
      "Current Epoch: 3 [14400/60000 (96%)]\tLoss: 0.004372624214738607\tTrain Accuracy: 98.91%\tTest Accuracy: 98.89%\n",
      "Epoch: 4\n",
      "Current Epoch: 4 [0/60000 (0%)]\tLoss: 0.006496995687484741\tTrain Accuracy: 100.00%\tTest Accuracy: 98.82%\n",
      "Current Epoch: 4 [1600/60000 (11%)]\tLoss: 0.018299352377653122\tTrain Accuracy: 99.16%\tTest Accuracy: 98.90%\n",
      "Current Epoch: 4 [3200/60000 (21%)]\tLoss: 0.007144471630454063\tTrain Accuracy: 99.20%\tTest Accuracy: 98.63%\n",
      "Current Epoch: 4 [4800/60000 (32%)]\tLoss: 0.005765455309301615\tTrain Accuracy: 99.13%\tTest Accuracy: 98.87%\n",
      "Current Epoch: 4 [6400/60000 (43%)]\tLoss: 0.03069089911878109\tTrain Accuracy: 99.11%\tTest Accuracy: 98.77%\n",
      "Current Epoch: 4 [8000/60000 (53%)]\tLoss: 0.005951112136244774\tTrain Accuracy: 99.11%\tTest Accuracy: 98.88%\n",
      "Current Epoch: 4 [9600/60000 (64%)]\tLoss: 0.003373837796971202\tTrain Accuracy: 99.12%\tTest Accuracy: 98.99%\n",
      "Current Epoch: 4 [11200/60000 (75%)]\tLoss: 0.023371484130620956\tTrain Accuracy: 99.13%\tTest Accuracy: 98.86%\n",
      "Current Epoch: 4 [12800/60000 (85%)]\tLoss: 0.02480505406856537\tTrain Accuracy: 99.13%\tTest Accuracy: 98.75%\n",
      "Current Epoch: 4 [14400/60000 (96%)]\tLoss: 0.01675509661436081\tTrain Accuracy: 99.12%\tTest Accuracy: 98.65%\n",
      "Epoch: 5\n",
      "Current Epoch: 5 [0/60000 (0%)]\tLoss: 0.006310792174190283\tTrain Accuracy: 100.00%\tTest Accuracy: 98.69%\n",
      "Current Epoch: 5 [1600/60000 (11%)]\tLoss: 0.013410387560725212\tTrain Accuracy: 99.57%\tTest Accuracy: 99.12%\n",
      "Current Epoch: 5 [3200/60000 (21%)]\tLoss: 0.006408920977264643\tTrain Accuracy: 99.36%\tTest Accuracy: 99.13%\n",
      "Current Epoch: 5 [4800/60000 (32%)]\tLoss: 0.013270748779177666\tTrain Accuracy: 99.36%\tTest Accuracy: 98.90%\n",
      "Current Epoch: 5 [6400/60000 (43%)]\tLoss: 0.003959373105317354\tTrain Accuracy: 99.35%\tTest Accuracy: 99.05%\n",
      "Current Epoch: 5 [8000/60000 (53%)]\tLoss: 0.013974633067846298\tTrain Accuracy: 99.34%\tTest Accuracy: 98.89%\n",
      "Current Epoch: 5 [9600/60000 (64%)]\tLoss: 0.02734512649476528\tTrain Accuracy: 99.33%\tTest Accuracy: 99.02%\n",
      "Current Epoch: 5 [11200/60000 (75%)]\tLoss: 0.05382203683257103\tTrain Accuracy: 99.33%\tTest Accuracy: 98.89%\n",
      "Current Epoch: 5 [12800/60000 (85%)]\tLoss: 0.001319193746894598\tTrain Accuracy: 99.33%\tTest Accuracy: 99.07%\n",
      "Current Epoch: 5 [14400/60000 (96%)]\tLoss: 0.014843069016933441\tTrain Accuracy: 99.32%\tTest Accuracy: 98.81%\n",
      "Epoch: 6\n",
      "Current Epoch: 6 [0/60000 (0%)]\tLoss: 0.03249940648674965\tTrain Accuracy: 98.44%\tTest Accuracy: 98.69%\n",
      "Current Epoch: 6 [1600/60000 (11%)]\tLoss: 0.011445845477283001\tTrain Accuracy: 99.55%\tTest Accuracy: 99.06%\n",
      "Current Epoch: 6 [3200/60000 (21%)]\tLoss: 0.02013380266726017\tTrain Accuracy: 99.53%\tTest Accuracy: 99.02%\n",
      "Current Epoch: 6 [4800/60000 (32%)]\tLoss: 0.0008995005046017468\tTrain Accuracy: 99.52%\tTest Accuracy: 98.97%\n",
      "Current Epoch: 6 [6400/60000 (43%)]\tLoss: 0.032838791608810425\tTrain Accuracy: 99.50%\tTest Accuracy: 98.77%\n",
      "Current Epoch: 6 [8000/60000 (53%)]\tLoss: 0.005605276208370924\tTrain Accuracy: 99.48%\tTest Accuracy: 98.45%\n",
      "Current Epoch: 6 [9600/60000 (64%)]\tLoss: 0.0038302370812743902\tTrain Accuracy: 99.46%\tTest Accuracy: 99.13%\n",
      "Current Epoch: 6 [11200/60000 (75%)]\tLoss: 0.0015075824921950698\tTrain Accuracy: 99.45%\tTest Accuracy: 98.95%\n",
      "Current Epoch: 6 [12800/60000 (85%)]\tLoss: 0.0010070651769638062\tTrain Accuracy: 99.45%\tTest Accuracy: 98.93%\n",
      "Current Epoch: 6 [14400/60000 (96%)]\tLoss: 0.001982257002964616\tTrain Accuracy: 99.43%\tTest Accuracy: 98.94%\n",
      "Epoch: 7\n",
      "Current Epoch: 7 [0/60000 (0%)]\tLoss: 0.0030714424792677164\tTrain Accuracy: 100.00%\tTest Accuracy: 99.03%\n",
      "Current Epoch: 7 [1600/60000 (11%)]\tLoss: 0.05348201468586922\tTrain Accuracy: 99.50%\tTest Accuracy: 98.97%\n",
      "Current Epoch: 7 [3200/60000 (21%)]\tLoss: 0.005171149969100952\tTrain Accuracy: 99.47%\tTest Accuracy: 98.76%\n",
      "Current Epoch: 7 [4800/60000 (32%)]\tLoss: 0.015773896127939224\tTrain Accuracy: 99.55%\tTest Accuracy: 98.85%\n",
      "Current Epoch: 7 [6400/60000 (43%)]\tLoss: 0.01056936476379633\tTrain Accuracy: 99.52%\tTest Accuracy: 98.97%\n",
      "Current Epoch: 7 [8000/60000 (53%)]\tLoss: 0.017855651676654816\tTrain Accuracy: 99.53%\tTest Accuracy: 99.10%\n",
      "Current Epoch: 7 [9600/60000 (64%)]\tLoss: 0.020721159875392914\tTrain Accuracy: 99.53%\tTest Accuracy: 98.94%\n",
      "Current Epoch: 7 [11200/60000 (75%)]\tLoss: 0.004858899861574173\tTrain Accuracy: 99.53%\tTest Accuracy: 99.06%\n",
      "Current Epoch: 7 [12800/60000 (85%)]\tLoss: 0.008061893284320831\tTrain Accuracy: 99.53%\tTest Accuracy: 98.89%\n",
      "Current Epoch: 7 [14400/60000 (96%)]\tLoss: 0.010771130211651325\tTrain Accuracy: 99.52%\tTest Accuracy: 99.02%\n",
      "Epoch: 8\n",
      "Current Epoch: 8 [0/60000 (0%)]\tLoss: 4.9492951802676544e-05\tTrain Accuracy: 100.00%\tTest Accuracy: 99.01%\n",
      "Current Epoch: 8 [1600/60000 (11%)]\tLoss: 0.001080116257071495\tTrain Accuracy: 99.63%\tTest Accuracy: 99.10%\n",
      "Current Epoch: 8 [3200/60000 (21%)]\tLoss: 0.0037355488166213036\tTrain Accuracy: 99.55%\tTest Accuracy: 99.00%\n",
      "Current Epoch: 8 [4800/60000 (32%)]\tLoss: 0.060576826333999634\tTrain Accuracy: 99.56%\tTest Accuracy: 99.10%\n",
      "Current Epoch: 8 [6400/60000 (43%)]\tLoss: 0.0064748115837574005\tTrain Accuracy: 99.61%\tTest Accuracy: 99.02%\n",
      "Current Epoch: 8 [8000/60000 (53%)]\tLoss: 0.005651978775858879\tTrain Accuracy: 99.59%\tTest Accuracy: 99.15%\n",
      "Current Epoch: 8 [9600/60000 (64%)]\tLoss: 0.0017504714196547866\tTrain Accuracy: 99.60%\tTest Accuracy: 99.09%\n",
      "Current Epoch: 8 [11200/60000 (75%)]\tLoss: 0.008605016395449638\tTrain Accuracy: 99.58%\tTest Accuracy: 99.07%\n",
      "Current Epoch: 8 [12800/60000 (85%)]\tLoss: 0.002004378940910101\tTrain Accuracy: 99.59%\tTest Accuracy: 99.10%\n",
      "Current Epoch: 8 [14400/60000 (96%)]\tLoss: 0.009261289611458778\tTrain Accuracy: 99.60%\tTest Accuracy: 99.09%\n",
      "Epoch: 9\n",
      "Current Epoch: 9 [0/60000 (0%)]\tLoss: 0.010512525215744972\tTrain Accuracy: 100.00%\tTest Accuracy: 99.02%\n",
      "Current Epoch: 9 [1600/60000 (11%)]\tLoss: 0.000900881364941597\tTrain Accuracy: 99.80%\tTest Accuracy: 99.10%\n",
      "Current Epoch: 9 [3200/60000 (21%)]\tLoss: 0.1332276612520218\tTrain Accuracy: 99.81%\tTest Accuracy: 98.95%\n",
      "Current Epoch: 9 [4800/60000 (32%)]\tLoss: 0.004738082643598318\tTrain Accuracy: 99.76%\tTest Accuracy: 99.14%\n",
      "Current Epoch: 9 [6400/60000 (43%)]\tLoss: 0.0045384629629552364\tTrain Accuracy: 99.72%\tTest Accuracy: 99.07%\n",
      "Current Epoch: 9 [8000/60000 (53%)]\tLoss: 0.001779124024324119\tTrain Accuracy: 99.69%\tTest Accuracy: 99.06%\n",
      "Current Epoch: 9 [9600/60000 (64%)]\tLoss: 0.006721684243530035\tTrain Accuracy: 99.68%\tTest Accuracy: 99.03%\n",
      "Current Epoch: 9 [11200/60000 (75%)]\tLoss: 0.025413133203983307\tTrain Accuracy: 99.68%\tTest Accuracy: 99.10%\n",
      "Current Epoch: 9 [12800/60000 (85%)]\tLoss: 0.00044158732634969056\tTrain Accuracy: 99.66%\tTest Accuracy: 99.08%\n",
      "Current Epoch: 9 [14400/60000 (96%)]\tLoss: 0.020487798377871513\tTrain Accuracy: 99.64%\tTest Accuracy: 99.06%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Assuming CNN class and accuracy function are defined elsewhere\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "\n",
    "# instantiate the model\n",
    "net = CNN().to(device)\n",
    "\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# start training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch:', epoch)\n",
    "    # store results for the current epoch\n",
    "    train_rights = []\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # transfer tensors to the selected device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        net.train()  # train the network\n",
    "        output = net(data)  # forward pass\n",
    "        loss = criterion(output, target)  # calculate loss\n",
    "        optimizer.zero_grad()  # reset gradients\n",
    "        loss.backward()  # backward pass\n",
    "        optimizer.step()  # optimization step\n",
    "        right = accuracy(output, target)  # calculate accuracy\n",
    "        train_rights.append(right)\n",
    "\n",
    "        # print progress and validation accuracy every 100 batches\n",
    "        if batch_idx % 100 == 0:\n",
    "            net.eval()  # put network in evaluation mode\n",
    "            val_rights = []\n",
    "\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = net(data)  # forward pass\n",
    "                right = accuracy(output, target)  # calculate accuracy\n",
    "                val_rights.append(right)\n",
    "\n",
    "            # accuracy calculation\n",
    "            train_r = (sum([tup[0] for tup in train_rights]), sum([tup[1] for tup in train_rights]))\n",
    "            val_r = (sum([tup[0] for tup in val_rights]), sum([tup[1] for tup in val_rights]))\n",
    "\n",
    "            print(f'Current Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
    "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item()}\\t'\n",
    "                  f'Train Accuracy: {100. * train_r[0] / train_r[1]:.2f}%\\t'\n",
    "                  f'Test Accuracy: {100. * val_r[0] / val_r[1]:.2f}%')\n",
    "\n",
    "# 2m 58.8s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "time cost by cpu:gpu = 2:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "(tensor(64, device='cuda:0'), 64)\n",
      "(tensor(9914, device='cuda:0'), 10000)\n",
      "Current Epoch: 9 [0/60000 (0%)]\tLoss: 0.008301625959575176\tTrain Accuracy: 100.00%\tTest Accuracy: 99.14%\n",
      "(tensor(19255, device='cuda:0'), 19264)\n",
      "(tensor(9915, device='cuda:0'), 10000)\n",
      "Current Epoch: 9 [4800/60000 (32%)]\tLoss: 0.00019448064267635345\tTrain Accuracy: 99.95%\tTest Accuracy: 99.15%\n",
      "(tensor(38425, device='cuda:0'), 38464)\n",
      "(tensor(9904, device='cuda:0'), 10000)\n",
      "Current Epoch: 9 [9600/60000 (64%)]\tLoss: 0.0006056005950085819\tTrain Accuracy: 99.90%\tTest Accuracy: 99.04%\n",
      "(tensor(57581, device='cuda:0'), 57664)\n",
      "(tensor(9896, device='cuda:0'), 10000)\n",
      "Current Epoch: 9 [14400/60000 (96%)]\tLoss: 0.0017653277609497309\tTrain Accuracy: 99.86%\tTest Accuracy: 98.96%\n"
     ]
    }
   ],
   "source": [
    "print('Epoch:', 1)\n",
    "# store results for the current epoch\n",
    "train_rights = []\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    # transfer tensors to the selected device\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    net.train()  # train the network\n",
    "    output = net(data)  # forward pass\n",
    "    loss = criterion(output, target)  # calculate loss\n",
    "    optimizer.zero_grad()  # reset gradients\n",
    "    loss.backward()  # backward pass\n",
    "    optimizer.step()  # optimization step\n",
    "    right = accuracy(output, target)  # calculate accuracy\n",
    "    train_rights.append(right)\n",
    "\n",
    "    # print progress and validation accuracy every 100 batches\n",
    "    if batch_idx % 300 == 0:\n",
    "        net.eval()  # put network in evaluation mode\n",
    "        val_rights = []\n",
    "\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = net(data)  # forward pass\n",
    "            right = accuracy(output, target)  # calculate accuracy\n",
    "            \n",
    "            val_rights.append(right)\n",
    "\n",
    "        # accuracy calculation\n",
    "        train_r = (sum([tup[0] for tup in train_rights]), sum([tup[1] for tup in train_rights]))\n",
    "        val_r = (sum([tup[0] for tup in val_rights]), sum([tup[1] for tup in val_rights]))\n",
    "        print(train_r)\n",
    "        print(val_r)\n",
    "        print(f'Current Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
    "                f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item()}\\t'\n",
    "                f'Train Accuracy: {100. * train_r[0] / train_r[1]:.2f}%\\t'\n",
    "                f'Test Accuracy: {100. * val_r[0] / val_r[1]:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
